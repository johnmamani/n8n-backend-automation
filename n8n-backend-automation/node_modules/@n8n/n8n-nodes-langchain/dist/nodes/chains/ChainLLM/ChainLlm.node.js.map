{"version":3,"sources":["../../../../nodes/chains/ChainLLM/ChainLlm.node.ts"],"sourcesContent":["import type { BaseLanguageModel } from '@langchain/core/language_models/base';\nimport type {\n\tIExecuteFunctions,\n\tINodeExecutionData,\n\tINodeType,\n\tINodeTypeDescription,\n} from 'n8n-workflow';\nimport { NodeApiError, NodeConnectionTypes, NodeOperationError } from 'n8n-workflow';\n\nimport { getPromptInputByType } from '@utils/helpers';\nimport { getOptionalOutputParser } from '@utils/output_parsers/N8nOutputParser';\n\n// Import from centralized module\nimport {\n\texecuteChain,\n\tformatResponse,\n\tgetInputs,\n\tnodeProperties,\n\ttype MessageTemplate,\n} from './methods';\nimport {\n\tgetCustomErrorMessage as getCustomOpenAiErrorMessage,\n\tisOpenAiError,\n} from '../../vendors/OpenAi/helpers/error-handling';\n\n/**\n * Basic LLM Chain Node Implementation\n * Allows connecting to language models with optional structured output parsing\n */\nexport class ChainLlm implements INodeType {\n\tdescription: INodeTypeDescription = {\n\t\tdisplayName: 'Basic LLM Chain',\n\t\tname: 'chainLlm',\n\t\ticon: 'fa:link',\n\t\ticonColor: 'black',\n\t\tgroup: ['transform'],\n\t\tversion: [1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6],\n\t\tdescription: 'A simple chain to prompt a large language model',\n\t\tdefaults: {\n\t\t\tname: 'Basic LLM Chain',\n\t\t\tcolor: '#909298',\n\t\t},\n\t\tcodex: {\n\t\t\talias: ['LangChain'],\n\t\t\tcategories: ['AI'],\n\t\t\tsubcategories: {\n\t\t\t\tAI: ['Chains', 'Root Nodes'],\n\t\t\t},\n\t\t\tresources: {\n\t\t\t\tprimaryDocumentation: [\n\t\t\t\t\t{\n\t\t\t\t\t\turl: 'https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/',\n\t\t\t\t\t},\n\t\t\t\t],\n\t\t\t},\n\t\t},\n\t\tinputs: `={{ ((parameter) => { ${getInputs.toString()}; return getInputs(parameter) })($parameter) }}`,\n\t\toutputs: [NodeConnectionTypes.Main],\n\t\tcredentials: [],\n\t\tproperties: nodeProperties,\n\t};\n\n\t/**\n\t * Main execution method for the node\n\t */\n\tasync execute(this: IExecuteFunctions): Promise<INodeExecutionData[][]> {\n\t\tthis.logger.debug('Executing Basic LLM Chain');\n\t\tconst items = this.getInputData();\n\t\tconst returnData: INodeExecutionData[] = [];\n\n\t\t// Process each input item\n\t\tfor (let itemIndex = 0; itemIndex < items.length; itemIndex++) {\n\t\t\ttry {\n\t\t\t\t// Get the language model\n\t\t\t\tconst llm = (await this.getInputConnectionData(\n\t\t\t\t\tNodeConnectionTypes.AiLanguageModel,\n\t\t\t\t\t0,\n\t\t\t\t)) as BaseLanguageModel;\n\n\t\t\t\t// Get output parser if configured\n\t\t\t\tconst outputParser = await getOptionalOutputParser(this);\n\n\t\t\t\t// Get user prompt based on node version\n\t\t\t\tlet prompt: string;\n\n\t\t\t\tif (this.getNode().typeVersion <= 1.3) {\n\t\t\t\t\tprompt = this.getNodeParameter('prompt', itemIndex) as string;\n\t\t\t\t} else {\n\t\t\t\t\tprompt = getPromptInputByType({\n\t\t\t\t\t\tctx: this,\n\t\t\t\t\t\ti: itemIndex,\n\t\t\t\t\t\tinputKey: 'text',\n\t\t\t\t\t\tpromptTypeKey: 'promptType',\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\t// Validate prompt\n\t\t\t\tif (prompt === undefined) {\n\t\t\t\t\tthrow new NodeOperationError(this.getNode(), \"The 'prompt' parameter is empty.\");\n\t\t\t\t}\n\n\t\t\t\t// Get chat messages if configured\n\t\t\t\tconst messages = this.getNodeParameter(\n\t\t\t\t\t'messages.messageValues',\n\t\t\t\t\titemIndex,\n\t\t\t\t\t[],\n\t\t\t\t) as MessageTemplate[];\n\n\t\t\t\t// Execute the chain\n\t\t\t\tconst responses = await executeChain({\n\t\t\t\t\tcontext: this,\n\t\t\t\t\titemIndex,\n\t\t\t\t\tquery: prompt,\n\t\t\t\t\tllm,\n\t\t\t\t\toutputParser,\n\t\t\t\t\tmessages,\n\t\t\t\t});\n\n\t\t\t\t// If the node version is 1.6(and LLM is using `response_format: json_object`) or higher or an output parser is configured,\n\t\t\t\t//  we unwrap the response and return the object directly as JSON\n\t\t\t\tconst shouldUnwrapObjects = this.getNode().typeVersion >= 1.6 || !!outputParser;\n\t\t\t\t// Process each response and add to return data\n\t\t\t\tresponses.forEach((response) => {\n\t\t\t\t\treturnData.push({\n\t\t\t\t\t\tjson: formatResponse(response, shouldUnwrapObjects),\n\t\t\t\t\t});\n\t\t\t\t});\n\t\t\t} catch (error) {\n\t\t\t\t// Handle OpenAI specific rate limit errors\n\t\t\t\tif (error instanceof NodeApiError && isOpenAiError(error.cause)) {\n\t\t\t\t\tconst openAiErrorCode: string | undefined = (error.cause as any).error?.code;\n\t\t\t\t\tif (openAiErrorCode) {\n\t\t\t\t\t\tconst customMessage = getCustomOpenAiErrorMessage(openAiErrorCode);\n\t\t\t\t\t\tif (customMessage) {\n\t\t\t\t\t\t\terror.message = customMessage;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Continue on failure if configured\n\t\t\t\tif (this.continueOnFail()) {\n\t\t\t\t\treturnData.push({ json: { error: error.message }, pairedItem: { item: itemIndex } });\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tthrow error;\n\t\t\t}\n\t\t}\n\n\t\treturn [returnData];\n\t}\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAOA,0BAAsE;AAEtE,qBAAqC;AACrC,6BAAwC;AAGxC,qBAMO;AACP,4BAGO;AAMA,MAAM,SAA8B;AAAA,EAApC;AACN,uBAAoC;AAAA,MACnC,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,WAAW;AAAA,MACX,OAAO,CAAC,WAAW;AAAA,MACnB,SAAS,CAAC,GAAG,KAAK,KAAK,KAAK,KAAK,KAAK,GAAG;AAAA,MACzC,aAAa;AAAA,MACb,UAAU;AAAA,QACT,MAAM;AAAA,QACN,OAAO;AAAA,MACR;AAAA,MACA,OAAO;AAAA,QACN,OAAO,CAAC,WAAW;AAAA,QACnB,YAAY,CAAC,IAAI;AAAA,QACjB,eAAe;AAAA,UACd,IAAI,CAAC,UAAU,YAAY;AAAA,QAC5B;AAAA,QACA,WAAW;AAAA,UACV,sBAAsB;AAAA,YACrB;AAAA,cACC,KAAK;AAAA,YACN;AAAA,UACD;AAAA,QACD;AAAA,MACD;AAAA,MACA,QAAQ,yBAAyB,yBAAU,SAAS,CAAC;AAAA,MACrD,SAAS,CAAC,wCAAoB,IAAI;AAAA,MAClC,aAAa,CAAC;AAAA,MACd,YAAY;AAAA,IACb;AAAA;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,UAAkE;AACvE,SAAK,OAAO,MAAM,2BAA2B;AAC7C,UAAM,QAAQ,KAAK,aAAa;AAChC,UAAM,aAAmC,CAAC;AAG1C,aAAS,YAAY,GAAG,YAAY,MAAM,QAAQ,aAAa;AAC9D,UAAI;AAEH,cAAM,MAAO,MAAM,KAAK;AAAA,UACvB,wCAAoB;AAAA,UACpB;AAAA,QACD;AAGA,cAAM,eAAe,UAAM,gDAAwB,IAAI;AAGvD,YAAI;AAEJ,YAAI,KAAK,QAAQ,EAAE,eAAe,KAAK;AACtC,mBAAS,KAAK,iBAAiB,UAAU,SAAS;AAAA,QACnD,OAAO;AACN,uBAAS,qCAAqB;AAAA,YAC7B,KAAK;AAAA,YACL,GAAG;AAAA,YACH,UAAU;AAAA,YACV,eAAe;AAAA,UAChB,CAAC;AAAA,QACF;AAGA,YAAI,WAAW,QAAW;AACzB,gBAAM,IAAI,uCAAmB,KAAK,QAAQ,GAAG,kCAAkC;AAAA,QAChF;AAGA,cAAM,WAAW,KAAK;AAAA,UACrB;AAAA,UACA;AAAA,UACA,CAAC;AAAA,QACF;AAGA,cAAM,YAAY,UAAM,6BAAa;AAAA,UACpC,SAAS;AAAA,UACT;AAAA,UACA,OAAO;AAAA,UACP;AAAA,UACA;AAAA,UACA;AAAA,QACD,CAAC;AAID,cAAM,sBAAsB,KAAK,QAAQ,EAAE,eAAe,OAAO,CAAC,CAAC;AAEnE,kBAAU,QAAQ,CAAC,aAAa;AAC/B,qBAAW,KAAK;AAAA,YACf,UAAM,+BAAe,UAAU,mBAAmB;AAAA,UACnD,CAAC;AAAA,QACF,CAAC;AAAA,MACF,SAAS,OAAO;AAEf,YAAI,iBAAiB,wCAAgB,qCAAc,MAAM,KAAK,GAAG;AAChE,gBAAM,kBAAuC,MAAM,MAAc,OAAO;AACxE,cAAI,iBAAiB;AACpB,kBAAM,oBAAgB,sBAAAA,uBAA4B,eAAe;AACjE,gBAAI,eAAe;AAClB,oBAAM,UAAU;AAAA,YACjB;AAAA,UACD;AAAA,QACD;AAGA,YAAI,KAAK,eAAe,GAAG;AAC1B,qBAAW,KAAK,EAAE,MAAM,EAAE,OAAO,MAAM,QAAQ,GAAG,YAAY,EAAE,MAAM,UAAU,EAAE,CAAC;AACnF;AAAA,QACD;AAEA,cAAM;AAAA,MACP;AAAA,IACD;AAEA,WAAO,CAAC,UAAU;AAAA,EACnB;AACD;","names":["getCustomOpenAiErrorMessage"]}